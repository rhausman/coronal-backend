{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## simple command\n",
    "# python rhrad_online_alerts.py --heart_rate hr.csv --steps steps.csv\n",
    "\n",
    "## full command\n",
    "#  python rhrad_online_alerts.py --heart_rate pbb_fitbit_oldProtocol_hr.csv --steps pbb_fitbit_oldProtocol_steps.csv --myphd_id pbb_RHR_online --figure1 pbb_RHR_online_anomalies.pdf --anomalies pbb_RHR_online_anomalies.csv --symptom_date 2020-01-10 --diagnosis_date 2020-01-11 --outliers_fraction 0.1 --random_seed 10  --baseline_window 744 --sliding_window 1 --alerts pbb_RHR_online_alerts.csv --figure2 pbb_RHR_online_alerts.pdf\n",
    "\n",
    "# python rhrad_online_alerts.py --heart_rate pbb_fitbit_oldProtocol_hr.csv \\\n",
    "# --steps pbb_fitbit_oldProtocol_steps.csv \\\n",
    "# --myphd_id pbb_RHR_online \\\n",
    "# --figure1 pbb_RHR_online_anomalies.pdf \\\n",
    "# --anomalies pbb_RHR_online_anomalies.csv \\\n",
    "# --symptom_date 2020-01-10 --diagnosis_date 2020-01-11 \\\n",
    "# --outliers_fraction 0.1 \\\n",
    "# --random_seed 10  \\\n",
    "# --baseline_window 744 --sliding_window 1 \n",
    "# --alerts pbb_RHR_online_alerts.csv \\\n",
    "# --figure2 pbb_RHR_online_alerts.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import sys \n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "#%matplotlib inline\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.covariance import EllipticEnvelope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitbit_oldProtocol_hr = \"AHYIJDV_hr.csv\"\n",
    "fitbit_oldProtocol_steps = \"AHYIJDV_steps.csv\"\n",
    "myphd_id = \"myphd_id\"\n",
    "myphd_id_anomalies = \"myphd_id_anomalies.csv\"\n",
    "myphd_id_figure1 = \"myphd_id_anomalies.pdf\"\n",
    "symptom_date = \"NaN\"\n",
    "diagnosis_date = \"NaN\"\n",
    "RANDOM_SEED = 10\n",
    "outliers_fraction =  0.1\n",
    "baseline_window = 744\n",
    "sliding_window = 1\n",
    "myphd_id_alerts = \"myphd_id_alerts.csv\"\n",
    "myphd_id_figure2 = \"myphd_id_alerts.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RHRAD_online:\n",
    "\n",
    "    # Infer resting heart rate ------------------------------------------------------\n",
    "\n",
    "    def resting_heart_rate(self, heartrate, steps):\n",
    "        \"\"\"\n",
    "        This function uses heart rate and steps data to infer resting heart rate.\n",
    "        It filters the heart rate with steps that are zero and also 12 minutes ahead.\n",
    "        \"\"\"\n",
    "        # heart rate data\n",
    "        df_hr = pd.read_csv(fitbit_oldProtocol_hr)\n",
    "        df_hr = df_hr.set_index('datetime')\n",
    "        df_hr.index.name = None\n",
    "        df_hr.index = pd.to_datetime(df_hr.index)\n",
    "\n",
    "        # steps data\n",
    "        df_steps = pd.read_csv(fitbit_oldProtocol_steps)\n",
    "        df_steps = df_steps.set_index('datetime')\n",
    "        df_steps.index.name = None\n",
    "        df_steps.index = pd.to_datetime(df_steps.index)\n",
    "\n",
    "        # merge dataframes\n",
    "        #df_hr = df_hr.resample('1min').median()\n",
    "        #df_steps = df_steps.resample('1min').median()\n",
    "\n",
    "        df1 = pd.merge(df_hr, df_steps, left_index=True, right_index=True)\n",
    "        df1 = df1.resample('1min').mean()\n",
    "        df1 = df1.dropna()\n",
    "        \n",
    "        # define RHR as the HR measurements recorded when there were zero steps taken during a rolling time window of the preceding 12 minutes (including the current minute)\n",
    "        df1['steps_window_12'] = df1['steps'].rolling(12).sum()\n",
    "        df1 = df1.loc[(df1['steps_window_12'] == 0)]\n",
    "        return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RHRAD_online()\n",
    "\n",
    "df1 = model.resting_heart_rate(fitbit_oldProtocol_hr, fitbit_oldProtocol_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>heartrate</th>\n",
       "      <th>steps</th>\n",
       "      <th>steps_window_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-08-12 02:09:00</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-12 02:10:00</th>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-12 02:12:00</th>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-12 02:13:00</th>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-12 02:14:00</th>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-25 23:20:00</th>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-25 23:21:00</th>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-25 23:22:00</th>\n",
       "      <td>58.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-25 23:23:00</th>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-25 23:24:00</th>\n",
       "      <td>59.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5908 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     heartrate  steps  steps_window_12\n",
       "2020-08-12 02:09:00       55.0    0.0              0.0\n",
       "2020-08-12 02:10:00       54.0    0.0              0.0\n",
       "2020-08-12 02:12:00       57.0    0.0              0.0\n",
       "2020-08-12 02:13:00       56.0    0.0              0.0\n",
       "2020-08-12 02:14:00       52.0    0.0              0.0\n",
       "...                        ...    ...              ...\n",
       "2020-10-25 23:20:00       57.0    0.0              0.0\n",
       "2020-10-25 23:21:00       57.0    0.0              0.0\n",
       "2020-10-25 23:22:00       58.0    0.0              0.0\n",
       "2020-10-25 23:23:00       57.0    0.0              0.0\n",
       "2020-10-25 23:24:00       59.0    0.0              0.0\n",
       "\n",
       "[5908 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unused code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df2 = model.pre_processing(df1)\n",
    "sdHR = df2[['heartrate']]\n",
    "sdSteps = df2[['steps_window_12']]\n",
    "data_seasnCorec = model.seasonality_correction(sdHR, sdSteps)\n",
    "data_seasnCorec += 0.1\n",
    "dfs = []\n",
    "data_train = []\n",
    "data_test = []\n",
    "model.online_anomaly_detection(data_seasnCorec, baseline_window, sliding_window)\n",
    "results = model.merge_test_results(data_test)\n",
    "positive_anomalies = model.positive_anomalies(results)\n",
    "alerts = model.create_alerts(positive_anomalies, results, fitbit_oldProtocol_hr)\n",
    "test_alerts = model.merge_alerts(results, alerts)\n",
    "model.visualize(results, positive_anomalies, test_alerts, symptom_date, diagnosis_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RHRAD_online:\n",
    "\n",
    "    # Infer resting heart rate ------------------------------------------------------\n",
    "\n",
    "    def resting_heart_rate(self, heartrate, steps):\n",
    "        \"\"\"\n",
    "        This function uses heart rate and steps data to infer resting heart rate.\n",
    "        It filters the heart rate with steps that are zero and also 12 minutes ahead.\n",
    "        \"\"\"\n",
    "        # heart rate data\n",
    "        df_hr = pd.read_csv(fitbit_oldProtocol_hr)\n",
    "        df_hr = df_hr.set_index('datetime')\n",
    "        df_hr.index.name = None\n",
    "        df_hr.index = pd.to_datetime(df_hr.index)\n",
    "\n",
    "        # steps data\n",
    "        df_steps = pd.read_csv(fitbit_oldProtocol_steps)\n",
    "        df_steps = df_steps.set_index('datetime')\n",
    "        df_steps.index.name = None\n",
    "        df_steps.index = pd.to_datetime(df_steps.index)\n",
    "\n",
    "        # merge dataframes\n",
    "        #df_hr = df_hr.resample('1min').median()\n",
    "        #df_steps = df_steps.resample('1min').median()\n",
    "\n",
    "        df1 = pd.merge(df_hr, df_steps, left_index=True, right_index=True)\n",
    "        df1 = df1.resample('1min').mean()\n",
    "        df1 = df1.dropna()\n",
    "        \n",
    "        # define RHR as the HR measurements recorded when there were zero steps taken during a rolling time window of the preceding 12 minutes (including the current minute)\n",
    "        df1['steps_window_12'] = df1['steps'].rolling(12).sum()\n",
    "        df1 = df1.loc[(df1['steps_window_12'] == 0)]\n",
    "        return df1\n",
    "\n",
    "    # Pre-processing ------------------------------------------------------\n",
    "\n",
    "    def pre_processing(self, resting_heart_rate):\n",
    "        \"\"\"\n",
    "        This function takes resting heart rate data and applies moving averages to smooth the data and \n",
    "        downsamples to one hour by taking the avegare values\n",
    "        \"\"\"\n",
    "        # smooth data\n",
    "        df_nonas = df1.dropna()\n",
    "        df1_rom = df_nonas.rolling(400).mean()\n",
    "        # resample\n",
    "        df1_resmp = df1_rom.resample('1H').mean()\n",
    "        df2 = df1_resmp.drop(['steps'], axis=1)\n",
    "        df2 = df2.dropna()\n",
    "        return df2\n",
    "\n",
    "    # Seasonality correction ------------------------------------------------------\n",
    "\n",
    "    def seasonality_correction(self, resting_heart_rate, steps):\n",
    "        \"\"\"\n",
    "        This function takes output pre-processing and applies seasonality correction\n",
    "        \"\"\"\n",
    "        sdHR_decomposition = seasonal_decompose(sdHR, model='additive', freq=1)\n",
    "        sdSteps_decomposition = seasonal_decompose(sdSteps, model='additive', freq=1)\n",
    "        sdHR_decomp = pd.DataFrame(sdHR_decomposition.resid + sdHR_decomposition.trend)\n",
    "        sdHR_decomp.rename(columns={sdHR_decomp.columns[0]:'heartrate'}, inplace=True)\n",
    "        sdSteps_decomp = pd.DataFrame(sdSteps_decomposition.resid + sdSteps_decomposition.trend)\n",
    "        sdSteps_decomp.rename(columns={sdSteps_decomp.columns[0]:'steps_window_12'}, inplace=True)\n",
    "        frames = [sdHR_decomp, sdSteps_decomp]\n",
    "        data = pd.concat(frames, axis=1)\n",
    "        return data\n",
    "\n",
    "    # Train model and predict anomalies ------------------------------------------------------\n",
    "\n",
    "    def online_anomaly_detection(self, data_seasnCorec, baseline_window, sliding_window):\n",
    "        \"\"\"\n",
    "        # split the data, standardize the data inside a sliding window \n",
    "        # parameters - 1 month baseline window and 1 hour sliding window\n",
    "        # fit the model and predict the test set\n",
    "        \"\"\"\n",
    "        for i in range(baseline_window, len(data_seasnCorec)):\n",
    "            data_train_w = data_seasnCorec[i-baseline_window:i] \n",
    "            # train data normalization ------------------------------------------------------\n",
    "            data_train_w += 0.1\n",
    "            standardizer = StandardScaler().fit(data_train_w.values)\n",
    "            data_train_scaled = standardizer.transform(data_train_w.values)\n",
    "            data_train_scaled_features = pd.DataFrame(data_train_scaled, index=data_train_w.index, columns=data_train_w.columns)\n",
    "            data = pd.DataFrame(data_train_scaled_features)\n",
    "            data_1 = pd.DataFrame(data).fillna(0)\n",
    "            data_1['steps'] = '0'\n",
    "            data_1['steps_window_12'] = (data_1['steps']) \n",
    "            data_train_w = data_1\n",
    "            data_train.append(data_train_w)\n",
    "\n",
    "            data_test_w = data_seasnCorec[i:i+sliding_window] \n",
    "            # test data normalization ------------------------------------------------------\n",
    "            data_test_w += 0.1\n",
    "            data_test_scaled = standardizer.transform(data_test_w.values)\n",
    "            data_scaled_features = pd.DataFrame(data_test_scaled, index=data_test_w.index, columns=data_test_w.columns)\n",
    "            data = pd.DataFrame(data_scaled_features)\n",
    "            data_1 = pd.DataFrame(data).fillna(0)\n",
    "            data_1['steps'] = '0'\n",
    "            data_1['steps_window_12'] = (data_1['steps']) \n",
    "            data_test_w = data_1\n",
    "            data_test.append(data_test_w)\n",
    "\n",
    "            # fit the model  ------------------------------------------------------\n",
    "            model = EllipticEnvelope(random_state=RANDOM_SEED,\n",
    "                                     contamination=outliers_fraction,\n",
    "                                     support_fraction=0.7).fit(data_train_w)\n",
    "            # predict the test set\n",
    "            preds = model.predict(data_test_w)\n",
    "            #preds = preds.rename(lambda x: 'anomaly' if x == 0 else x, axis=1)\n",
    "            dfs.append(preds)\n",
    "\n",
    "\n",
    "    # Merge predictions ------------------------------------------------------\n",
    "\n",
    "    def merge_test_results(self, data_test):\n",
    "        \"\"\"\n",
    "        Merge predictions\n",
    "        \"\"\"\n",
    "        # concat all test data (from sliding window) with their datetime index and others\n",
    "        data_test = pd.concat(data_test)\n",
    "        # merge predicted anomalies from test data with their corresponding index and other features \n",
    "        preds = pd.DataFrame(dfs)\n",
    "        preds = preds.rename(lambda x: 'anomaly' if x == 0 else x, axis=1)\n",
    "        data_test_df = pd.DataFrame(data_test)\n",
    "        data_test_df = data_test_df.reset_index()\n",
    "        data_test_preds = data_test_df.join(preds)\n",
    "        return data_test_preds\n",
    "\n",
    "\n",
    "    # Positive Anomalies -----------------------------------------------------------------\n",
    "        \"\"\"\n",
    "        Selects anomalies in positive direction and saves in a CSV file\n",
    "        \"\"\"\n",
    "    def positive_anomalies(self, data):\n",
    "        a = data.loc[data['anomaly'] == -1, ('index', 'heartrate')]\n",
    "        positive_anomalies = a[(a['heartrate']> 0)]\n",
    "        # Anomaly results\n",
    "        positive_anomalies['Anomalies'] = myphd_id\n",
    "        positive_anomalies.columns = ['datetime', 'std.rhr', 'name']\n",
    "        positive_anomalies.to_csv(myphd_id_anomalies, header=True) \n",
    "        return positive_anomalies\n",
    "\n",
    "\n",
    "    # Alerts  ------------------------------------------------------\n",
    "\n",
    "    def create_alerts(self, anomalies, data, fitbit_oldProtocol_hr):\n",
    "        \"\"\"\n",
    "        # creates alerts at every 24 hours and send at 9PM.\n",
    "        # visualise alerts\n",
    "        \"\"\"\n",
    "        # function to assign different alert names\n",
    "        # summarize hourly alerts\n",
    "        def alert_types(alert):\n",
    "            if alert['alerts'] >=6:\n",
    "                return 'RED'\n",
    "            elif alert['alerts'] >=1:\n",
    "                return 'YELLOW'\n",
    "            else:\n",
    "                return 'GREEN'\n",
    "\n",
    "        # summarize hourly alerts\n",
    "        #anomalies.columns = ['datetime', 'std.rhr', 'name']\n",
    "        anomalies = anomalies[['datetime']]\n",
    "        anomalies['datetime'] = pd.to_datetime(anomalies['datetime'], errors='coerce')\n",
    "        anomalies['alerts'] = 1\n",
    "        anomalies = anomalies.set_index('datetime')\n",
    "        anomalies = anomalies[~anomalies.index.duplicated(keep='first')]\n",
    "        anomalies = anomalies.sort_index()\n",
    "        alerts = anomalies.groupby(pd.Grouper(freq = '24H',  base=21)).cumsum()\n",
    "        # apply alert_types function\n",
    "        alerts['alert_type'] = alerts.apply(alert_types, axis=1)\n",
    "        alerts_reset = alerts.reset_index()\n",
    "        #print(alerts_reset)\n",
    "        # save alerts\n",
    "        #alerts.to_csv(myphd_id_alerts, mode='a', header=True) \n",
    "\n",
    "\n",
    "        # summarize hourly alerts to daily alerts\n",
    "        daily_alerts = alerts_reset.resample('24H', on='datetime', base=21, label='right').count()\n",
    "        daily_alerts = daily_alerts.drop(['datetime'], axis=1)\n",
    "        #print(daily_alerts)\n",
    "\n",
    "        # function to assign different alert names\n",
    "        def alert_types(alert):\n",
    "            if alert['alert_type'] >=6:\n",
    "                return 'RED'\n",
    "            elif alert['alert_type'] >=1:\n",
    "                return 'YELLOW'\n",
    "            else:\n",
    "                return 'GREEN'\n",
    "\n",
    "        # apply alert_types function\n",
    "        daily_alerts['alert_type'] = daily_alerts.apply(alert_types, axis=1)\n",
    "        \n",
    "\n",
    "        # merge missing 'datetime' with 'alerts' as zero aka GREEN\n",
    "        data1 = data[['index']]\n",
    "        data1['alert_type'] = 0\n",
    "        data1 = data1.rename(columns={\"index\": \"datetime\"})\n",
    "        data1['datetime'] = pd.to_datetime(data1['datetime'], errors='coerce')\n",
    "        data1 = data1.resample('24H', on='datetime', base=21, label='right').count()\n",
    "        data1 = data1.drop(data1.columns[[0,1]], axis=1)\n",
    "        data1 = data1.reset_index()\n",
    "        data1['alert_type'] = 0\n",
    "\n",
    "        data3 = pd.merge(data1, daily_alerts, on='datetime', how='outer')\n",
    "        data4 = data3[['datetime', 'alert_type_y']]\n",
    "        data4 = data4.rename(columns={ \"alert_type_y\": \"alert_type\"})\n",
    "        daily_alerts = data4.fillna(\"GREEN\")\n",
    "        daily_alerts = daily_alerts.set_index('datetime')\n",
    "        daily_alerts = daily_alerts.sort_index()\n",
    "  \n",
    "\n",
    "        # merge alerts with main data and pass 'NA' when there is a missing day instead of 'GREEN'\n",
    "        df_hr = pd.read_csv(fitbit_oldProtocol_hr)\n",
    "\n",
    "        df_hr['datetime'] = pd.to_datetime(df_hr['datetime'], errors='coerce')\n",
    "        df_hr = df_hr.resample('24H', on='datetime', base=21, label='right').mean()\n",
    "        df_hr = df_hr.reset_index()\n",
    "        df_hr = df_hr.set_index('datetime')\n",
    "        df_hr.index.name = None\n",
    "        df_hr.index = pd.to_datetime(df_hr.index)\n",
    "        \n",
    "        df3 = pd.merge(df_hr, daily_alerts, how='outer', left_index=True, right_index=True)\n",
    "        df3 = df3[df3.alert_type.notnull()]\n",
    "        df3.loc[df3.heartrate.isna(), 'alert_type'] = pd.NA\n",
    "\n",
    "\n",
    "        daily_alerts = df3.drop('heartrate', axis=1)\n",
    "        daily_alerts = daily_alerts.reset_index()\n",
    "        daily_alerts = daily_alerts.rename(columns={\"index\": \"datetime\"})\n",
    "        daily_alerts.to_csv(myphd_id_alerts,  na_rep='NA', header=True) \n",
    "\n",
    "        \n",
    "        # visualize hourly alerts\n",
    "        #colors = {'RED': 'red', 'YELLOW': 'yellow', 'GREEN': ''}\n",
    "        #ax = alerts['alerts'].plot(kind='bar', color=[colors[i] for i in alerts['alert_type']],figsize=(20,4))\n",
    "        #ax.set_ylabel('No.of Alerts \\n', fontsize = 14) # Y label\n",
    "        #ax.axvline(pd.to_datetime(symptom_date), color='grey', zorder=1, linestyle='--', marker=\"v\" ) # Symptom date \n",
    "        #ax.axvline(pd.to_datetime(diagnosis_date), color='purple',zorder=1, linestyle='--', marker=\"v\") # Diagnosis date\n",
    "        #plt.xticks(fontsize=4, rotation=90)\n",
    "        #plt.tight_layout()\n",
    "        #ax.figure.savefig(myphd_id_figure2, bbox_inches = \"tight\")\n",
    "        return daily_alerts\n",
    "\n",
    "\n",
    "    # Merge alerts  ------------------------------------------------------\n",
    "\n",
    "    def merge_alerts(self, data_test, alerts):\n",
    "        \"\"\"\n",
    "        Merge  alerts  with their corresponding index and other features \n",
    "        \"\"\"\n",
    "\n",
    "        data_test = data_test.reset_index()\n",
    "        data_test['index'] = pd.to_datetime(data_test['index'], errors='coerce')\n",
    "        test_alerts = alerts\n",
    "        test_alerts = test_alerts.rename(columns={\"datetime\": \"index\"})\n",
    "        test_alerts['index'] = pd.to_datetime(test_alerts['index'], errors='coerce')\n",
    "        test_alerts = pd.merge(data_test, test_alerts, how='outer', on='index')\n",
    "        test_alerts.fillna(0, inplace=True)\n",
    "        #print(test_alerts)\n",
    "        return test_alerts\n",
    "\n",
    "    \n",
    "    # Visualization and save predictions ------------------------------------------------------\n",
    "\n",
    "    def visualize(self, results, positive_anomalies, test_alerts, symptom_date, diagnosis_date):\n",
    "        \"\"\"\n",
    "        visualize all the data with anomalies and alerts\n",
    "        \"\"\"\n",
    "        try:\n",
    "\n",
    "            with plt.style.context('fivethirtyeight'):\n",
    "\n",
    "                fig, ax = plt.subplots(1, figsize=(80,15))\n",
    "               \n",
    "                ax.bar(test_alerts['index'], test_alerts['heartrate'], linestyle='-', color='midnightblue', lw=6, width=0.01)\n",
    "\n",
    "                colors = {0:'', 'RED': 'red', 'YELLOW': 'yellow', 'GREEN': 'lightgreen'}\n",
    "        \n",
    "                for i in range(len(test_alerts)):\n",
    "                    v = colors.get(test_alerts['alert_type'][i])\n",
    "                    ax.vlines(test_alerts['index'][i], test_alerts['heartrate'].min(), test_alerts['heartrate'].max(),  linestyle='dotted',  lw=4, color=v)\n",
    "                \n",
    "                #ax.scatter(positive_anomalies['index'],positive_anomalies['heartrate'], color='red', label='Anomaly', s=500)\n",
    "\n",
    "                ax.tick_params(axis='both', which='major', color='blue', labelsize=60)\n",
    "                ax.tick_params(axis='both', which='minor', color='blue', labelsize=60)\n",
    "                ax.set_title(myphd_id,fontweight=\"bold\", size=50) # Title\n",
    "                ax.set_ylabel('Std. RHR\\n', fontsize = 50) # Y label\n",
    "                ax.axvline(pd.to_datetime(symptom_date), color='grey', zorder=1, linestyle='--', marker=\"v\" , markersize=22, lw=6) # Symptom date \n",
    "                ax.axvline(pd.to_datetime(diagnosis_date), color='purple',zorder=1, linestyle='--', marker=\"v\" , markersize=22, lw=6) # Diagnosis date\n",
    "                ax.tick_params(axis='both', which='major', labelsize=60)\n",
    "                ax.tick_params(axis='both', which='minor', labelsize=60)\n",
    "                ax.xaxis.set_major_locator(mdates.DayLocator(interval=7))\n",
    "                ax.grid(zorder=0)\n",
    "                ax.grid(True)\n",
    "                plt.xticks(fontsize=30, rotation=90)\n",
    "                plt.yticks(fontsize=50)\n",
    "                ax.patch.set_facecolor('white')\n",
    "                fig.patch.set_facecolor('white')   \n",
    "                figure = fig.savefig(myphd_id_figure1, bbox_inches='tight')                             \n",
    "                return figure\n",
    "\n",
    "        except:\n",
    "            with plt.style.context('fivethirtyeight'):\n",
    "\n",
    "                fig, ax = plt.subplots(1, figsize=(80,15))\n",
    "\n",
    "                ax.bar(test_alerts['index'], test_alerts['heartrate'], linestyle='-', color='midnightblue', lw=6, width=0.01)\n",
    "\n",
    "                colors = {0:'', 'RED': 'red', 'YELLOW': 'yellow', 'GREEN': 'lightgreen'}\n",
    "        \n",
    "                for i in range(len(test_alerts)):\n",
    "                    v = colors.get(test_alerts['alert_type'][i])\n",
    "                    ax.vlines(test_alerts['index'][i], test_alerts['heartrate'].min(), test_alerts['heartrate'].max(),  linestyle='dotted',  lw=4, color=v)\n",
    " \n",
    "                #ax.scatter(positive_anomalies['index'],positive_anomalies['heartrate'], color='red', label='Anomaly', s=500)\n",
    "\n",
    "                ax.tick_params(axis='both', which='major', color='blue', labelsize=60)\n",
    "                ax.tick_params(axis='both', which='minor', color='blue', labelsize=60)\n",
    "                ax.set_title(myphd_id,fontweight=\"bold\", size=50) # Title\n",
    "                ax.set_ylabel('Std. RHR\\n', fontsize = 50) # Y label\n",
    "                ax.tick_params(axis='both', which='major', labelsize=60)\n",
    "                ax.tick_params(axis='both', which='minor', labelsize=60)\n",
    "                ax.xaxis.set_major_locator(mdates.DayLocator(interval=7))\n",
    "                ax.grid(zorder=0)\n",
    "                ax.grid(True)\n",
    "                plt.xticks(fontsize=30, rotation=90)\n",
    "                plt.yticks(fontsize=50)\n",
    "                ax.patch.set_facecolor('white')\n",
    "                fig.patch.set_facecolor('white')     \n",
    "                figure = fig.savefig(myphd_id_figure1, bbox_inches='tight')       \n",
    "                return figure\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
